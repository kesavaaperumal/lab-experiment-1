sudo apt update
sudo apt install openjdk-11-jdk -y
java -version
wget https://downloads.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz
tar -xvzf spark-3.5.6-bin-hadoop3.tgz
mv spark-3.5.6-bin-hadoop3 spark

nano ~/.bashrc

export HADOOP_HOME=$HOME/hadoop
export SPARK_HOME=$HOME/spark
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin:$SPARK_HOME/bin
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
source ~/.bashrc

java -version

hadoop version

spark-shell --version

mkdir ~/sparkinput
cd ~/sparkinput
nano sample.txt
Hello world
Hello Spark
Hello Hadoop
spark-shell
scala>val counts = sc.textFile("sample.txt")
  .flatMap(line => line.split(" "))
  .map(word => (word, 1))
  .reduceByKey(_ + _)
counts.collect().foreach(println)

